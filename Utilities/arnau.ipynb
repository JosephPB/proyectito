{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Convolutional Generative Adversarial Networks with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In this tutorial, we will try to build a GAN that is able to generate human faces with TensorFlow. Sounds scary, doesn’t it?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used Libraries:\n",
    "* matplotlib\n",
    "* PIL / Pillow\n",
    "* numpy\n",
    "* requests\n",
    "* tqdm\n",
    "* TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A helper function will automatically download the CelebA dataset to get you up and running quickly. Be sure to have matplotlib installed to actually see the images. The download is 1.7GB large, so be sure to have enough disk space and a stable internet connection ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import helper\n",
    "\n",
    "data_dir = './images_64'\n",
    "\n",
    "# Let's download the dataset\n",
    "#helper.download_celeb_a()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The CelebA Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CelebFaces Attributes Dataset dataset contains over 200,000 celebrity images each with 40 attribute annotations. At this point, we are also going to define to function for batch generation. This function will load our images and give us an array of images according to a batch size we are going to set later. To get some better results, we will crop the images, so that only the faces are showing. We will also normalize the images so that their values are in a range from -0,5 to +0,5. At last, we are going to downscale the images to 28x28 after that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from glob import glob\n",
    "from matplotlib import pyplot\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Image configuration\n",
    "IMAGE_HEIGHT = 64\n",
    "IMAGE_WIDTH = 64\n",
    "data_files = glob(\"images_64/*.jpg\")#glob(os.path.join(data_dir, 'celebA/*.jpg'))\n",
    "shape = len(data_files), IMAGE_WIDTH, IMAGE_HEIGHT, 1\n",
    "def get_image(image_path, width, height, mode):\n",
    "    \"\"\"\n",
    "    Read image from image_path\n",
    "    \"\"\"\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    if image.size != (width, height):\n",
    "        # Remove most pixels that aren't part of a face\n",
    "        face_width = face_height = 108\n",
    "        j = (image.size[0] - face_width) // 2\n",
    "        i = (image.size[1] - face_height) // 2\n",
    "        image = image.crop([j, i, j + face_width, i + face_height])\n",
    "        image = image.resize([width, height], Image.BILINEAR)\n",
    "\n",
    "    return np.array(image.convert(mode))\n",
    "\n",
    "def get_batch(image_files, width, height, mode='L'):\n",
    "    \"\"\"\n",
    "    Get a single image\n",
    "    \"\"\"\n",
    "    data_batch = np.array(\n",
    "        [get_image(sample_file, width, height, mode) for sample_file in image_files]).astype(np.float32)\n",
    "\n",
    "    # Make sure the images are in 4 dimensions\n",
    "    if len(data_batch.shape) < 4:\n",
    "        data_batch = data_batch.reshape(data_batch.shape + (1,))\n",
    "    return data_batch\n",
    "\n",
    "def get_batches(batch_size):\n",
    "    \"\"\"\n",
    "    Generate batches\n",
    "    \"\"\"\n",
    "    IMAGE_MAX_VALUE = 1\n",
    "\n",
    "\n",
    "    current_index = 0\n",
    "    while current_index + batch_size <= shape[0]:\n",
    "        data_batch = get_batch(\n",
    "            data_files[current_index:current_index + batch_size],\n",
    "            *shape[1:3])\n",
    "\n",
    "        current_index += batch_size\n",
    "        yield data_batch / IMAGE_MAX_VALUE - 0.5\n",
    "        \n",
    "\n",
    "test_images = get_batch(glob('images/*.jpg')[:10], 64, 64)\n",
    "#pyplot.imshow(helper.images_square_grid(test_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining network input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can start defining our two networks, we are going to define our inputs. We are doing this to not clutter the training function any more than it already is. Here, we are simply defining TensorFlow Placeholders for our real and fake inputs and for the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arnau.quera-bofarull\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def model_inputs(image_width, image_height, image_channels, z_dim):\n",
    "    \"\"\"\n",
    "    Create the model inputs\n",
    "    \"\"\"\n",
    "    inputs_real = tf.placeholder(tf.float32, shape=(None, image_width, image_height, image_channels), name='input_real') \n",
    "    inputs_z = tf.placeholder(tf.float32, (None, z_dim), name='input_z')\n",
    "    learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "    \n",
    "    return inputs_real, inputs_z, learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The discriminator network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discriminator is the “art critic”, who tries to distinguish between real and fake images. Simply said, this is a convolutional neural network for image classification. The discriminator network consists of four convolutional layers. For every layer of the network, we are going to perform a convolution, then we are going to perform batch normalization to make the network faster and more accurate and finally, we are going to perform a Leaky ReLu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(images, reuse=False):\n",
    "    \"\"\"\n",
    "    Create the discriminator network\n",
    "    \"\"\"\n",
    "    alpha = 0.2\n",
    "    \n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        # using 4 layer network as in DCGAN Paper\n",
    "        \n",
    "        # Conv 1\n",
    "        conv1 = tf.layers.conv2d(images, 64, 5, 2, 'SAME')\n",
    "        lrelu1 = tf.maximum(alpha * conv1, conv1)\n",
    "        \n",
    "        # Conv 2\n",
    "        conv2 = tf.layers.conv2d(lrelu1, 128, 5, 2, 'SAME')\n",
    "        batch_norm2 = tf.layers.batch_normalization(conv2, training=True)\n",
    "        lrelu2 = tf.maximum(alpha * batch_norm2, batch_norm2)\n",
    "\n",
    "        # Conv 3\n",
    "        conv3 = tf.layers.conv2d(lrelu2, 256, 5, 2, 'SAME')\n",
    "        batch_norm3 = tf.layers.batch_normalization(conv3, training=True)\n",
    "        lrelu3 = tf.maximum(alpha * batch_norm3, batch_norm3)\n",
    "\n",
    "        # Flatten\n",
    "        flat = tf.reshape(lrelu3, (-1, 4*4*256))\n",
    "        \n",
    "        # Logits\n",
    "        logits = tf.layers.dense(flat, 1)\n",
    "        \n",
    "        # Output\n",
    "        out = tf.sigmoid(logits)\n",
    "\n",
    "        return out, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The generator network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generator goes the other way: It is the artist who is trying to fool the discriminator. This network consists of four deconvolutional layers. In here, we are doing the same as in the discriminator, just in the other direction. First, we take our input, called Z, and feed it into our first deconvolutional layer. Each deconvolutional layer performs a deconvolution and then performs batch normalization and a leaky ReLu as well. Then, we return the tanh activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z, out_channel_dim, is_train=True):\n",
    "    \"\"\"\n",
    "    Create the generator network\n",
    "    \"\"\"\n",
    "    alpha = 0.2\n",
    "    \n",
    "    with tf.variable_scope('generator', reuse=False if is_train==True else True):\n",
    "        # First fully connected layer\n",
    "        x_1 = tf.layers.dense(z, 4*4*1024)\n",
    "        \n",
    "        # Reshape it to start the convolutional stack\n",
    "        deconv_2 = tf.reshape(x_1, (-1, 4, 4, 1024))\n",
    "        batch_norm2 = tf.layers.batch_normalization(deconv_2, training=is_train)\n",
    "        lrelu2 = tf.maximum(alpha * batch_norm2, batch_norm2)\n",
    "        \n",
    "        # Deconv 1\n",
    "        deconv3 = tf.layers.conv2d_transpose(lrelu2, 512, 5 , 2, padding='SAME')\n",
    "\n",
    "        batch_norm3 = tf.layers.batch_normalization(deconv3, training=is_train)\n",
    "        lrelu3 = tf.maximum(alpha * batch_norm3, batch_norm3)\n",
    "\n",
    "        \n",
    "        # Deconv 2\n",
    "        deconv4 = tf.layers.conv2d_transpose(lrelu3, 256, 5, 2, padding='SAME')\n",
    "        batch_norm4 = tf.layers.batch_normalization(deconv4, training=is_train)\n",
    "        lrelu4 = tf.maximum(alpha * batch_norm4, batch_norm4)\n",
    "        \n",
    "          # Deconv 2\n",
    "        decon5 = tf.layers.conv2d_transpose(lrelu4, 128, 5,2, padding='SAME')\n",
    "        batch_norm5 = tf.layers.batch_normalization(decon5, training=is_train)\n",
    "        lrelu5 = tf.maximum(alpha * batch_norm5, batch_norm5)\n",
    "        \n",
    "                \n",
    "        # Output layer\n",
    "        logits = tf.layers.conv2d_transpose(lrelu4, out_channel_dim, (5,5), 4, padding='SAME')\n",
    "        \n",
    "        out = tf.tanh(logits)\n",
    "        \n",
    "        print(deconv_2.get_shape())\n",
    "\n",
    "        print(deconv3.get_shape())\n",
    "\n",
    "        print(deconv4.get_shape())\n",
    "                \n",
    "        print(logits.get_shape())\n",
    "\n",
    "\n",
    "        print(out.get_shape())\n",
    " \n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than just having a single loss function, we need to define three: The loss of the generator, the loss of the discriminator when using real images and the loss of the discriminator when using fake images. The sum of the fake image and real image loss is the overall discriminator loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(input_real, input_z, out_channel_dim):\n",
    "    \"\"\"\n",
    "    Get the loss for the discriminator and generator\n",
    "    \"\"\"\n",
    "    \n",
    "    label_smoothing = 0.9\n",
    "    \n",
    "    g_model = generator(input_z, out_channel_dim)\n",
    "    d_model_real, d_logits_real = discriminator(input_real)\n",
    "    d_model_fake, d_logits_fake = discriminator(g_model, reuse=True)\n",
    "    \n",
    "    d_loss_real = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real,\n",
    "                                                labels=tf.ones_like(d_model_real) * label_smoothing))\n",
    "    d_loss_fake = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n",
    "                                                labels=tf.zeros_like(d_model_fake)))\n",
    "    \n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "                                                  \n",
    "    g_loss = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n",
    "                                                labels=tf.ones_like(d_model_fake) * label_smoothing))\n",
    "    \n",
    "    \n",
    "    return d_loss, g_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than just having a single loss function, we need to define three: The loss of the generator, the loss of the discriminator when using real images and the loss of the discriminator when using fake images. The sum of the fake image and real image loss is the overall discriminator loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_opt(d_loss, g_loss, learning_rate, beta1):\n",
    "    \"\"\"\n",
    "    Get optimization operations\n",
    "    \"\"\"\n",
    "    t_vars = tf.trainable_variables()\n",
    "    d_vars = [var for var in t_vars if var.name.startswith('discriminator')]\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "\n",
    "    # Optimize\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): \n",
    "        d_train_opt = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(d_loss, var_list=d_vars)\n",
    "        g_train_opt = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(g_loss, var_list=g_vars)\n",
    "    return d_train_opt, g_train_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last step of our preparation, we are writing a small helper function to display the generated images in the notebook for us, using the matplotlib library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_generator_output(sess, n_images, input_z, out_channel_dim):\n",
    "    \"\"\"\n",
    "    Show example output for the generator\n",
    "    \"\"\"\n",
    "    z_dim = input_z.get_shape().as_list()[-1]\n",
    "    example_z = np.random.uniform(-1, 1, size=[n_images, z_dim])\n",
    "\n",
    "    samples = sess.run(\n",
    "        generator(input_z, out_channel_dim, False),\n",
    "        feed_dict={input_z: example_z})\n",
    "    #print(samples)\n",
    "    for image in samples:\n",
    "        pyplot.imshow(image[...,0], cmap = 'gray')\n",
    "    #pyplot.imshow(helper.images_square_grid(samples))\n",
    "        pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we just get our inputs, losses and optimizers which we defined before, call a TensorFlow session and run it batch per batch. Every 400 steps we are printing out the current progress by showing the generated image and loss. Now lean back and see the faces show up slowly but steady - and we mean slowly but steady! This progress can take up some hours based on your setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch_count, batch_size, z_dim, learning_rate, beta1, get_batches, data_shape):\n",
    "    \"\"\"\n",
    "    Train the GAN\n",
    "    \"\"\"\n",
    "    input_real, input_z, _ = model_inputs(data_shape[1], data_shape[2], data_shape[3], z_dim)\n",
    "    d_loss, g_loss = model_loss(input_real, input_z, data_shape[3])\n",
    "    d_opt, g_opt = model_opt(d_loss, g_loss, learning_rate, beta1)\n",
    "    \n",
    "    steps = 0\n",
    "    \n",
    "    with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for epoch_i in range(epoch_count):\n",
    "            for batch_images in get_batches(batch_size):\n",
    "                \n",
    "                # values range from -0.5 to 0.5, therefore scale to range -1, 1\n",
    "                batch_images = batch_images * 2\n",
    "                steps += 1\n",
    "            \n",
    "                batch_z = np.random.uniform(-1, 1, size=(batch_size, z_dim))\n",
    "                _ = sess.run(g_opt, feed_dict={input_real: batch_images, input_z: batch_z})\n",
    "                _ = sess.run(d_opt, feed_dict={input_real: batch_images, input_z: batch_z})\n",
    "                \n",
    "                if steps % 2 == 0:\n",
    "                    # At the end of every 10 epochs, get the losses and print them out\n",
    "                    train_loss_d = d_loss.eval({input_z: batch_z, input_real: batch_images})\n",
    "                    train_loss_g = g_loss.eval({input_z: batch_z})\n",
    "\n",
    "\n",
    "                    print(\"Epoch {}/{}...\".format(epoch_i+1, epochs),\n",
    "                          \"Discriminator Loss: {:.4f}...\".format(train_loss_d),\n",
    "                          \"Generator Loss: {:.4f}\".format(train_loss_g))\n",
    "                    \n",
    "                    _ = show_generator_output(sess, 1, input_z, data_shape[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 4, 4, 1024)\n",
      "(?, 8, 8, 512)\n",
      "(?, 16, 16, 256)\n",
      "(?, 64, 64, 1)\n",
      "(?, 64, 64, 1)\n",
      "Epoch 1/150... Discriminator Loss: 0.4998... Generator Loss: 2.3833\n",
      "(?, 4, 4, 1024)\n",
      "(?, 8, 8, 512)\n",
      "(?, 16, 16, 256)\n",
      "(?, 64, 64, 1)\n",
      "(?, 64, 64, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/150... Discriminator Loss: 0.4067... Generator Loss: 4.7131\n",
      "(?, 4, 4, 1024)\n",
      "(?, 8, 8, 512)\n",
      "(?, 16, 16, 256)\n",
      "(?, 64, 64, 1)\n",
      "(?, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "z_dim = 100\n",
    "learning_rate = 0.0002\n",
    "beta1 = 0.5\n",
    "epochs = 150\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    train(epochs, batch_size, z_dim, learning_rate, beta1, get_batches, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
